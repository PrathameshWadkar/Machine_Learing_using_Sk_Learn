{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1hLjnoA-Y4IEUz_2IZrmg1E2-IgFAnvOY","authorship_tag":"ABX9TyOJipUwpBNIBrgKE1jfnYrq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"v4P4Nb6BE_39","executionInfo":{"status":"ok","timestamp":1699081164982,"user_tz":-330,"elapsed":411,"user":{"displayName":"cdac_course","userId":"16993079997048252374"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import GridSearchCV,StratifiedKFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","source":["#Loading the HR Data\n","hr = pd.read_csv(\"/content/drive/MyDrive/KP_Module/Practical Machine Learning/Practise/Cases/human-resources-analytics/HR_comma_sep.csv\")\n","#since data is categorical we have to convert it into numeric values\n","#so using get_dummies we can convert feilds into numbers\n","dum_hr = pd.get_dummies(hr,drop_first=True)\n","X = dum_hr.drop('left',axis=1)\n","y = dum_hr['left']\n","\n","#Performing K-fold Cross-Validation\n","kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=23)\n","\n","#Initiating the All models\n","log_reg = LogisticRegression()\n","knn = KNeighborsClassifier()\n","gau = GaussianNB()\n","\n","#for Scaling the data we can use both the scaling methods\n","scalar = StandardScaler()\n","mn = MinMaxScaler()\n","\n","\n","################# KNN-Classifier ##############\n","\n","#since our KNN model is sequential we can use pipeline\n","pipe = Pipeline([('SCL',scalar),(\"KNN\",knn)])\n","#setting the required parameters for KNN Classifier\n","params = {'KNN__n_neighbors':np.arange(1,10),\n","          'SCL':[scalar,mn]}\n","\n","#to find Best Results we can use GridSearchCV\n","gcv = GridSearchCV(pipe,param_grid=params,scoring='neg_log_loss',cv=kfold)\n","\n","#fiting the model\n","gcv.fit(X,y)\n","\n","#Retriving the Best Result\n","print(gcv.best_params_)\n","print(gcv.best_score_)\n","\n","\n","############## Logistic Regression ############\n","\n","#setting the required parameters for Logistic Regression\n","params = {'penalty':['l1', 'l2', 'elasticnet'],\n","        'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n","        'l1_ratio':np.linspace(0,1,10), 'multi_class':['auto', 'ovr', 'multinomial']}\n","\n","gcv = GridSearchCV(log_reg,param_grid=params,cv=kfold,scoring='neg_log_loss')\n","gcv.fit(X,y)\n","print(gcv.best_params_)\n","print(gcv.best_score_)\n","\n","\n","############## Gaussian Naive Bayes Classifier ##############\n","#setting the required parameters for Gaussian Classifier\n","params = {'var_smoothing':np.arange(0,20)}\n","\n","#to find Best Results we can use GridSearchCV\n","gcv = GridSearchCV(gau,param_grid=params,cv=kfold,scoring='neg_log_loss')\n","#Fitting the Model\n","gcv.fit(X,y)\n","#Retriving the Best Results\n","\n","print(gcv.best_params_)\n","print(gcv.best_score_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJHZtkDHFSgR","executionInfo":{"status":"ok","timestamp":1699081749121,"user_tz":-330,"elapsed":567517,"user":{"displayName":"cdac_course","userId":"16993079997048252374"}},"outputId":"11d2785c-1e6b-4638-af99-5f64c725ec18"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["{'KNN__n_neighbors': 9, 'SCL': StandardScaler()}\n","-0.4961435410376313\n","{'l1_ratio': 0.0, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n","-0.4293021560377547\n","{'var_smoothing': 1}\n","-0.5390792065469133\n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","#Loading the HR Data\n","data = pd.read_csv(\"/content/drive/MyDrive/KP_Module/Practical Machine Learning/Practise/Cases/Image Segmentation/Image_Segmention.csv\")\n","#since data contains Multi classes we have to use LabelEncoder\n","#initiating the labelencoder\n","lbl = LabelEncoder()\n","\n","X = data.drop('Class',axis=1)\n","y = lbl.fit_transform(data['Class'])\n","\n","#Performing K-fold Cross-Validation\n","kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=23)\n","\n","#Initiating the All models\n","log_reg = LogisticRegression()\n","knn = KNeighborsClassifier()\n","gau = GaussianNB()\n","\n","#for Scaling the data we can use both the scaling methods\n","scalar = StandardScaler()\n","mn = MinMaxScaler()\n","\n","\n","################# KNN-Classifier ##############\n","\n","#since our KNN model is sequential we can use pipeline\n","pipe = Pipeline([('SCL',scalar),(\"KNN\",knn)])\n","#setting the required parameters for KNN Classifier\n","params = {'KNN__n_neighbors':np.arange(1,10),\n","          'SCL':[scalar,mn]}\n","\n","#to find Best Results we can use GridSearchCV\n","gcv = GridSearchCV(pipe,param_grid=params,scoring='neg_log_loss',cv=kfold)\n","\n","#fiting the model\n","gcv.fit(X,y)\n","\n","#Retriving the Best Result\n","print(gcv.best_params_)\n","print(gcv.best_score_)\n","\n","\n","# ############## Logistic Regression ############\n","\n","# #setting the required parameters for Logistic Regression\n","# params = {'penalty':['l1', 'l2', 'elasticnet'],\n","#         'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n","#         'l1_ratio':np.linspace(0,1,10), 'multi_class':['auto', 'ovr', 'multinomial']}\n","\n","# gcv = GridSearchCV(log_reg,param_grid=params,cv=kfold,scoring='neg_log_loss')\n","# gcv.fit(X,y)\n","# print(gcv.best_params_)\n","# print(gcv.best_score_)\n","\n","\n","############## Gaussian Naive Bayes Classifier ##############\n","#setting the required parameters for Gaussian Classifier\n","params = {'var_smoothing':np.arange(0,20)}\n","\n","#to find Best Results we can use GridSearchCV\n","gcv = GridSearchCV(gau,param_grid=params,cv=kfold,scoring='neg_log_loss')\n","#Fitting the Model\n","gcv.fit(X,y)\n","#Retriving the Best Results\n","\n","print(gcv.best_params_)\n","print(gcv.best_score_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmT1R54LH0yh","executionInfo":{"status":"ok","timestamp":1699081763144,"user_tz":-330,"elapsed":2218,"user":{"displayName":"cdac_course","userId":"16993079997048252374"}},"outputId":"4f4162ce-7277-40a9-aeb2-7ab83bf13b11"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["{'KNN__n_neighbors': 9, 'SCL': StandardScaler()}\n","-1.024611870341183\n","{'var_smoothing': 1}\n","-1.3548847857044024\n"]}]}]}